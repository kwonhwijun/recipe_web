{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc6ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레시피 데이터 불러오기\n",
    "import pickle\n",
    "with open('recipe_step_dict.pkl', 'rb') as f:\n",
    "    df1 = pickle.load(f)\n",
    "    \n",
    "# 식재료 벡터 불러오기\n",
    "import pickle\n",
    "with open('ingre.pickle', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "# 조리방법 사전 불러오기\n",
    "import pickle\n",
    "with open('unique_stems.pkl', 'rb') as f:\n",
    "    unique_stems = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레시피 데이터 가지고 데이터프레임 생성\n",
    "df2 = pd.DataFrame(df1.values(), columns=['recipe_step'])\n",
    "\n",
    "#recipe_step이 None인 행 삭제\n",
    "df2 = df2.dropna(subset=['recipe_step'])\n",
    "\n",
    "# 삭제 후 남는 행 확인\n",
    "df2[df2['recipe_step'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f570ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'recipe_step' 열 값이 빈 리스트인 행을 제거\n",
    "df2 = df2[df2['recipe_step'] != \"[]\"]\n",
    "\n",
    "# 인덱스 초기화\n",
    "df2 = df2.reset_index(drop=True)\n",
    "recipe_step = df2['recipe_step']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c71973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활용할 레시피 개수 선택\n",
    "recipe_step_30 = recipe_step[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레시피 데이터에 있는 모든 동사 추출\n",
    "stems = []\n",
    "for recipe_step in tqdm(recipe_step_30):\n",
    "    pos_list = okt.pos(recipe_step)\n",
    "    verbs = [word for word, pos in pos_list if pos.startswith('Verb')]\n",
    "    for verb in verbs:\n",
    "        stem = okt.morphs(verb, stem = True)\n",
    "        stems.append(stem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e07ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okt 형태소 분석기 초기화\n",
    "okt = Okt()\n",
    "\n",
    "# 동사와 명사 추출 후 동사는 어간으로 변환하는 함수\n",
    "def extract_verb_noun(text, food_vec):\n",
    "    vn = []\n",
    "    # 특수문자 및 숫자 제거\n",
    "    text = re.sub('[^가-힣\\s]', '', text)\n",
    "    # 형태소 분석\n",
    "    morphs = okt.pos(text)\n",
    "    # 명사와 동사 추출\n",
    "\n",
    "    for word, pos in morphs:\n",
    "        if pos.startswith('N') and word in test:  # 명사일 경우\n",
    "            vn.append(word)\n",
    "        elif pos.startswith('V'):  # 동사일 경우\n",
    "            # 동사 그대로 저장\n",
    "            verb_stem = okt.pos(word, stem=True)[0][0]\n",
    "            if verb_stem in unique_stems:\n",
    "                vn.append(verb_stem)\n",
    "    return vn\n",
    "\n",
    "# 조리방법(동사), 식재료(명사) 저장할 리스트 생성\n",
    "verb_noun_list = []\n",
    "\n",
    "# 데이터에 대해 함수 적용하여 리스트에 추가\n",
    "for text in tqdm(recipe_step_30):\n",
    "    verb_noun = extract_verb_noun(text, test)\n",
    "    verb_noun_list.append(verb_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레시피별 스텝을 5개 토큰으로 슬라이스\n",
    "slice_num = 5\n",
    "sliced_verb_noun = []\n",
    "for verb_noun in verb_noun_list:\n",
    "    # 5보다 적은 토큰을 가지고 있는 레시피는 ''를 채워서 5로 맞춰줌\n",
    "    if len(verb_noun) < 5:\n",
    "        for i in range(5-len(verb_noun)):\n",
    "            verb_noun.append('')\n",
    "    # 5개 이상의 레시피를 가진 레시피는 5개의 토큰으로 슬라이싱\n",
    "    split_lists = [verb_noun[i:i+slice_num] for i in range(len(verb_noun)-slice_num+1)]\n",
    "    sliced_verb_noun.append(split_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb630885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레시피 별로 5개 토큰으로 슬라이싱된 리스트 합치기\n",
    "# target 값인 y_list 생성\n",
    "sliced_verb_noun_total = []\n",
    "y_list = []\n",
    "for i, recipe in enumerate(sliced_verb_noun):\n",
    "    for step in recipe:\n",
    "        sliced_verb_noun_total.append(step)\n",
    "        y_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46b060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100차원의 0으로 채워진 배열 생성\n",
    "dim = 100\n",
    "zero_array = np.zeros(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa13966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사전의 크기와 임베딩 차원을 정의\n",
    "vocab_size = len(unique_stems)  # 단어 사전의 크기\n",
    "embedding_dim = 100  # 임베딩 차원\n",
    "\n",
    "# 임베딩 레이어 초기화\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# 레시피 별로 슬라이스 된 데이터를 조리방법은 임베딩 레이어를 통과시켜 100차원으로 변경하고 식재료는 미리 만들어둔 100차원 벡터로 변경\n",
    "recipe_vec = []\n",
    "for i, sliced_recipe in enumerate(tqdm(sliced_verb_noun_total)):\n",
    "    sliced_vec = []\n",
    "    for token in sliced_recipe:\n",
    "        if token in unique_stems:\n",
    "            index = unique_stems.index(token)\n",
    "            word_index = torch.LongTensor([index])\n",
    "            word_embed = embedding(word_index)\n",
    "            word_embed = word_embed.squeeze(0)\n",
    "            sliced_vec.append(word_embed.detach().numpy())\n",
    "            \n",
    "        elif token in test:\n",
    "            food_token = test[token]\n",
    "            sliced_vec.append(food_token)\n",
    "            \n",
    "        elif token == '':\n",
    "            sliced_vec.append(zero_array)\n",
    "\n",
    "    recipe_vec.append(sliced_vec)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data, output data 텐서로 변경\n",
    "recipe_tensor = torch.tensor(recipe_vec)\n",
    "y_tensor = torch.tensor(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dbd0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 생성\n",
    "dataset = torch.utils.data.TensorDataset(recipe_tensor, y_tensor)\n",
    "\n",
    "# 데이터로더 생성 (배치 활용)\n",
    "batch_size = 100  # 배치 크기\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac57b15c",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 튜닝 (그리드 서치)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e9d5ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1]  # 학습률에 대한 후보 값들\n",
    "hidden_sizes = [64, 128, 256] # hidden_size(은닉츠)에 대한 후보 값들\n",
    "best_loss_avg = 100 # 스타트 포인트\n",
    "epochs = 200\n",
    "\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for hidden in hidden_sizes:\n",
    "        # 하이퍼파라미터 설정\n",
    "        input_size_noun = 100 # 입력 크기\n",
    "        hidden_size_noun = hidden  # 은닉 상태 크기\n",
    "        output_size_noun = len(recipe_step_30)  # 출력 크기\n",
    "\n",
    "        # 식재료 RNN 모델 정의\n",
    "        class RNNNoun(nn.Module):\n",
    "            def __init__(self, input_size, hidden_size, output_size):\n",
    "                super(RNNNoun, self).__init__()\n",
    "                self.hidden_size = hidden_size # 은닉 상태 크기\n",
    "                self.dense = nn.Linear(input_size, hidden_size)  # Dense layer를 통해 input_size에서 hidden_size로 크기 선형 변환\n",
    "                self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True) # RNN층\n",
    "                self.fc = nn.Linear(hidden_size, output_size) # fully connected층(레시피 개수의 크기로 사이즈 변환)\n",
    "                self.softmax = nn.LogSoftmax(dim=1) # 소프트맥스 활성화 함수\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.dense(x)\n",
    "                h0 = torch.zeros(1, x.size(0), self.hidden_size) # 초기 은닉 상태 생성\n",
    "                out, _ = self.rnn(x, h0) # RNN층 실행\n",
    "                out1 = out[:, -1, :] # 마지막 RNN셀의 출력 선택(RNN 다대일 조건 추가)\n",
    "                out2 = self.fc(out1) # fully conncected층\n",
    "                out3 = self.softmax(out2) # 소프트맥스 층\n",
    "                return out1, out2, out3\n",
    "\n",
    "        # 모델 초기화\n",
    "        model_noun = RNNNoun(input_size_noun, hidden_size_noun, output_size_noun)\n",
    "        model_noun = model_noun.float() \n",
    "\n",
    "        # 손실 함수와 옵티마이저 설정\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer_noun = torch.optim.Adam(model_noun.parameters(), lr=learning_rate)\n",
    "\n",
    "        loss_list=[]\n",
    "        for epoch in range(epochs):\n",
    "            for batch in dataloader:  # 데이터로더에서 미니배치를 가져옴\n",
    "                inputs, targets = batch  # 입력과 타겟 로드\n",
    "                inputs = inputs.float()  # 입력 데이터 형식 변환\n",
    "\n",
    "                optimizer_noun.zero_grad()  # 옵티마이저 초기화\n",
    "                output1, output2, output3 = model_noun(inputs.squeeze(-1))  # 모델에 입력\n",
    "                loss = criterion(output3, targets)  # 손실 계산\n",
    "                loss.backward()  # 역전파를 통한 그래디언트 계산\n",
    "                optimizer_noun.step()  # 옵티마이저로 모델의 가중치 업데이트\n",
    "                loss_list.append(loss)\n",
    "\n",
    "            if (epoch+1) % 10 == 0:  # 10번의 에폭마다 손실 출력\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        loss_avg = average = sum(loss_list) / len(loss_list)\n",
    "        print(f\"Learning Rate: {learning_rate}\")\n",
    "        print(f\"Best Hidden Size: {hidden}\")\n",
    "        print(f\"평균 loss: {loss.item():.4f}\")\n",
    "        print()\n",
    "\n",
    "        if loss_avg < best_loss_avg:\n",
    "            best_loss_avg = loss_avg\n",
    "            best_lr = learning_rate\n",
    "            best_hidden_size = hidden\n",
    "            \n",
    "print(f\"Best_loss_avg: {best_loss_avg.item():.4f}\")\n",
    "print(f\"Best Learning Rate: {best_lr}\")\n",
    "print(f\"Best Hidden Size: {best_hidden_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25661261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 식재료 RNN 모델 정의\n",
    "class RNNNoun(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNNoun, self).__init__()\n",
    "        self.hidden_size = hidden_size # 은닉 상태 크기\n",
    "        self.dense = nn.Linear(input_size, hidden_size)  # Dense layer를 통해 input_size에서 hidden_size로 크기 선형 변환\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True) # RNN층\n",
    "        self.fc = nn.Linear(hidden_size, output_size) # fully connected층(레시피 개수의 크기로 사이즈 변환)\n",
    "        self.softmax = nn.LogSoftmax(dim=1) # 소프트맥스 활성화 함수\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense(x)\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size) # 초기 은닉 상태 생성\n",
    "        out, _ = self.rnn(x, h0) # RNN층 실행\n",
    "        out1 = out[:, -1, :] # 마지막 RNN셀의 출력 선택(RNN 다대일 조건 추가)\n",
    "        out2 = self.fc(out1) # fully conncected층\n",
    "        out3 = self.softmax(out2) # 소프트맥스 층\n",
    "        return out1, out2, out3\n",
    "            \n",
    "# 하이퍼파라미터 설정\n",
    "input_size_noun = 100 # 입력 크기\n",
    "hidden_size_noun = 256  # 은닉 상태 크기\n",
    "output_size_noun = len(recipe_step_30)  # 출력 크기\n",
    "\n",
    "# 모델 초기화\n",
    "model_noun = RNNNoun(input_size_noun, hidden_size_noun, output_size_noun)\n",
    "model_noun = model_noun.float() \n",
    "\n",
    "# 손실 함수와 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_noun = torch.optim.Adam(model_noun.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93968a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list=[]\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    for batch in dataloader:  # 데이터로더에서 미니배치를 가져옴\n",
    "        inputs, targets = batch  # 입력과 타겟 로드\n",
    "        inputs = inputs.float()  # 입력 데이터 형식 변환\n",
    "\n",
    "        optimizer_noun.zero_grad()  # 옵티마이저 초기화\n",
    "        output1, output2, output3 = model_noun(inputs.squeeze(-1))  # 모델에 입력\n",
    "        loss = criterion(output3, targets)  # 손실 계산\n",
    "        loss.backward()  # 역전파를 통한 그래디언트 계산\n",
    "        optimizer_noun.step()  # 옵티마이저로 모델의 가중치 업데이트\n",
    "        loss_list.append(loss)\n",
    "\n",
    "    if (epoch+1) % 10 == 0:  # 10번의 에폭마다 손실 출력\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
